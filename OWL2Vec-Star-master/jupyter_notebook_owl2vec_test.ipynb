{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a6c5ab",
   "metadata": {},
   "source": [
    "## Running OWL2Vec*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2658935d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Abhimanyu\n",
      "[nltk_data]     Acharya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "INFO: Access the ontology ...\n",
      "INFO: There are 1945 triples in the ontology\n",
      "INFO: Calculate the ontology projection ...\n",
      "INFO: Creating ontology graph projection...\n",
      "INFO: \tExtracting subsumption triples\n",
      "INFO: \t\tTime extracting subsumption: 0.7672033309936523 seconds \n",
      "INFO: \tExtracting equivalence triples\n",
      "INFO: \t\tTime extracting equivalences: 0.021520614624023438 seconds \n",
      "INFO: \tExtracting class membership triples.\n",
      "INFO: \t\tTime extracting class membership: 0.16771817207336426 seconds \n",
      "INFO: \tExtracting sameAs triples\n",
      "INFO: \t\tTime extracting sameAs: 0.0 seconds \n",
      "INFO: \tExtracting triples associated to hasBase\n",
      "INFO: \t\tTime extracting triples for property: 0.0664210319519043 seconds \n",
      "INFO: \tExtracting triples associated to hasIngredient\n",
      "INFO: \t\tTime extracting triples for property: 0.05237412452697754 seconds \n",
      "INFO: \tExtracting triples associated to isBaseOf\n",
      "INFO: \t\tTime extracting triples for property: 0.05624556541442871 seconds \n",
      "INFO: \tExtracting triples associated to hasCountryOfOrigin\n",
      "INFO: \t\tTime extracting triples for property: 0.07598114013671875 seconds \n",
      "INFO: \tExtracting triples associated to isIngredientOf\n",
      "INFO: \t\tTime extracting triples for property: 0.05113649368286133 seconds \n",
      "INFO: \tExtracting triples associated to hasSpiciness\n",
      "INFO: \t\tTime extracting triples for property: 0.1005406379699707 seconds \n",
      "INFO: \tExtracting triples associated to hasTopping\n",
      "INFO: \t\tTime extracting triples for property: 0.12888145446777344 seconds \n",
      "INFO: \tExtracting triples associated to isToppingOf\n",
      "INFO: \t\tTime extracting triples for property: 0.07113456726074219 seconds \n",
      "INFO: \tExtracting data property assertions\n",
      "INFO: \t\tTime extracting data property assertions: 0.0 seconds \n",
      "INFO: \tExtracting complex equivalence axioms\n",
      "INFO: \t\tTime extracting complex equivalence axioms: 0.01481318473815918 seconds \n",
      "INFO: \tExtracting annotations.\n",
      "INFO: \t\tTime extracting annotations: 0.3998451232910156 seconds \n",
      "INFO: Projection created into a Graph object (RDFlib library)\n",
      "INFO: Projection saved into turtle file: ./cache/projection.ttl\n",
      "INFO: Extract classes and individuals ...\n",
      "INFO: Extract axioms ...\n",
      "INFO: Extract annotations ...\n",
      "INFO: Generate URI document ...\n",
      "INFO: Extracted 582 walks for 104 seed entities\n",
      "INFO: Extracted 279 axiom sentences\n",
      "INFO: Generate literal document ...\n",
      "INFO: Extracted 34 annotation sentences\n",
      "INFO: Generate mixture document ...\n",
      "INFO: URI_Doc: 861, Lit_Doc: 1796, Mix_Doc: 861\n",
      "INFO: Time for document construction: 3.3752782344818115 seconds\n",
      "INFO: Train the language model ...\n",
      "INFO: collecting all words and their counts\n",
      "INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO: collected 777 word types from a corpus of 15617 raw words and 3518 sentences\n",
      "INFO: Creating a fresh vocabulary\n",
      "INFO: Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 777 unique words (100.00% of original 777, drops 0)', 'datetime': '2022-09-16T21:23:29.981866', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'prepare_vocab'}\n",
      "INFO: Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 15617 word corpus (100.00% of original 15617, drops 0)', 'datetime': '2022-09-16T21:23:29.981866', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'prepare_vocab'}\n",
      "INFO: deleting the raw counts dictionary of 777 items\n",
      "INFO: sample=0.001 downsamples 55 most-common words\n",
      "INFO: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 9067.614433658466 word corpus (58.1%% of prior 15617)', 'datetime': '2022-09-16T21:23:29.990281', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'prepare_vocab'}\n",
      "INFO: estimated required memory for 777 words and 85 dimensions: 916860 bytes\n",
      "INFO: resetting layer weights\n",
      "INFO: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-09-16T21:23:30.002458', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'build_vocab'}\n",
      "INFO: Word2Vec lifecycle event {'msg': 'training model with 20 workers on 777 vocabulary and 85 features, using sg=1 hs=0 sample=0.001 negative=25 window=5 shrink_windows=True', 'datetime': '2022-09-16T21:23:30.003472', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'train'}\n",
      "INFO: EPOCH 0: training on 15617 raw words (9032 effective words) took 0.0s, 306375 effective words/s\n",
      "INFO: EPOCH 1: training on 15617 raw words (9128 effective words) took 0.0s, 361812 effective words/s\n",
      "INFO: EPOCH 2: training on 15617 raw words (9093 effective words) took 0.0s, 329951 effective words/s\n",
      "INFO: EPOCH 3: training on 15617 raw words (9098 effective words) took 0.0s, 317076 effective words/s\n",
      "INFO: EPOCH 4: training on 15617 raw words (9021 effective words) took 0.0s, 349818 effective words/s\n",
      "INFO: EPOCH 5: training on 15617 raw words (9021 effective words) took 0.0s, 352215 effective words/s\n",
      "INFO: EPOCH 6: training on 15617 raw words (9038 effective words) took 0.0s, 349582 effective words/s\n",
      "INFO: EPOCH 7: training on 15617 raw words (9071 effective words) took 0.0s, 343342 effective words/s\n",
      "INFO: EPOCH 8: training on 15617 raw words (9083 effective words) took 0.0s, 354130 effective words/s\n",
      "INFO: EPOCH 9: training on 15617 raw words (9175 effective words) took 0.0s, 340106 effective words/s\n",
      "INFO: Word2Vec lifecycle event {'msg': 'training on 156170 raw words (90760 effective words) took 0.3s, 259944 effective words/s', 'datetime': '2022-09-16T21:23:30.352271', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'train'}\n",
      "INFO: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=777, vector_size=85, alpha=0.025>', 'datetime': '2022-09-16T21:23:30.353383', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'created'}\n",
      "INFO: Time for learning the language model: 0.38196682929992676 seconds\n",
      "INFO: Word2Vec lifecycle event {'fname_or_handle': './cache/output/ontology.embeddings', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-09-16T21:23:30.354376', 'gensim': '4.2.0', 'python': '3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'saving'}\n",
      "INFO: not storing attribute cum_table\n",
      "INFO: saved ./cache/output/ontology.embeddings\n",
      "INFO: storing 777x85 projection weights into ./cache/output/ontology.embeddings.txt\n"
     ]
    }
   ],
   "source": [
    "from owl2vec_star import owl2vec_star\n",
    "\n",
    "\n",
    "#Parameters:\n",
    "# ontology_file\n",
    "# config_file\n",
    "# uri_doc\n",
    "# lit_doc\n",
    "# mix_doc\n",
    "gensim_model = owl2vec_star.extract_owl2vec_model(\"./case_studies/pizza/pizza.owl\", \"./default.cfg\", True, True, True)\n",
    "\n",
    "output_folder=\"./cache/output/\"\n",
    "\n",
    "#Gensim format\n",
    "gensim_model.save(output_folder+\"ontology.embeddings\")\n",
    "    #Txt format\n",
    "gensim_model.wv.save_word2vec_format(output_folder+\"ontology.embeddings.txt\", binary=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a78df2",
   "metadata": {},
   "source": [
    "## Loading embeddings and getting similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fdbcf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: loading KeyedVectors object from ./cache/output/ontology.embeddings\n",
      "INFO: loading wv recursively from ./cache/output/ontology.embeddings.wv.* with mmap=r\n",
      "INFO: setting ignored attribute cum_table to None\n",
      "INFO: Word2Vec lifecycle event {'fname': './cache/output/ontology.embeddings', 'datetime': '2022-04-03T18:28:17.538248', 'gensim': '4.1.2', 'python': '3.8.10 (default, Mar 15 2022, 12:22:08) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-107-generic-x86_64-with-glibc2.29', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'pizza'\n",
      "[ 0.11139922  0.03455254  0.15158105  0.6114894   0.20663601  0.53395736\n",
      " -0.09197029 -0.07173101  0.1752342  -0.65811926 -0.01860704  0.04644626\n",
      "  0.1417845  -0.03679806 -0.2661091   0.10978213  0.07950623 -0.7604301\n",
      " -0.10540137  0.27380154 -0.13372116 -0.02536337  0.05202136  0.41834542\n",
      "  0.3444666  -0.8851259  -0.13122185  0.2619441  -0.3702318  -0.00967073\n",
      " -0.26868883 -0.3947839  -0.44641    -0.4967901   0.0247598  -0.84458625\n",
      "  0.31117314 -0.01431737 -0.49218348  0.21242924  0.4751569  -0.3522823\n",
      "  0.06369893 -0.2756807   0.17864463 -0.27719304 -0.01182104  0.6601959\n",
      "  0.28241694 -0.11273695  0.4635236   0.03246771  0.18720752 -0.3095463\n",
      "  0.3554481  -0.01066254 -0.13979104 -0.09713667 -0.08568931  0.11690582\n",
      "  0.8871984  -0.3686109  -0.08434672  0.43349743 -0.06122519  0.2322311\n",
      "  0.18166268 -0.1607971  -0.39743292 -0.08293543  0.41001576 -0.09654567\n",
      " -0.17758472 -0.1504669   0.30046737 -0.02178798  0.5750125  -0.0110304\n",
      " -0.07889778 -0.36994055  0.41333762  0.3452365  -0.6243669   0.28717917\n",
      " -0.15630476 -0.01276457 -0.3755662  -0.27718842  0.33268133  0.13209507\n",
      "  0.42390737  0.69995517  0.3696406   0.13451871 -0.02866815 -0.31370863\n",
      " -0.2556705  -0.30294833 -0.06758998 -0.10825583]\n",
      "0.48374757\n",
      "0.80984086\n",
      "[('rosa pizza', 0.7967075109481812), ('parmese pizza', 0.7939520478248596), ('unclosedpizza', 0.784817099571228), ('margherita pizza', 0.7771976590156555), ('mushroom pizza', 0.7761094570159912), ('veneziana pizza', 0.7617127299308777), ('sundried tomato', 0.7604901194572449), ('soho pizza', 0.757476270198822), ('american pizza', 0.749670147895813), ('caprina pizza', 0.7450791001319885)]\n",
      "[('unclosedpizza', 0.9122495055198669), ('unclosed', 0.9057228565216064), ('http://www.co-ode.org/ontologies/pizza/pizza.owl#Margherita', 0.9049196243286133), ('rosa pizza', 0.8869567513465881), ('rosa', 0.8840981721878052), ('margherita pizza', 0.8824605941772461), ('sundried tomato', 0.8810267448425293), ('veneziana pizza', 0.8807700872421265), ('mushroom pizza', 0.8781152367591858), ('caprina pizza', 0.8700227737426758)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "#Embedding vectors generated above\n",
    "model = KeyedVectors.load(\"./cache/output/ontology.embeddings\", mmap='r')\n",
    "wv = model.wv\n",
    "\n",
    "vector = wv['pizza']  # Get numpy vector of a word\n",
    "print(\"Vector for 'pizza'\")\n",
    "print(vector)\n",
    "\n",
    "#cosine similarity\n",
    "similarity = wv.similarity('pizza', 'http://www.co-ode.org/ontologies/pizza/pizza.owl#Pizza')\n",
    "print(similarity)\n",
    "\n",
    "similarity = wv.similarity('http://www.co-ode.org/ontologies/pizza/pizza.owl#Margherita', 'margherita')\n",
    "print(similarity)\n",
    "\n",
    "\n",
    "#Most similar cosine similarity\n",
    "result = wv.most_similar(positive=['margherita', 'pizza'])\n",
    "print(result)\n",
    "\n",
    "#Most similar entities: cosmul\n",
    "result = wv.most_similar_cosmul(positive=['margherita'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cdbe3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
